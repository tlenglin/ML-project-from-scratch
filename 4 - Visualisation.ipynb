{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a408e6305d8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_df.colums.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing about missing values is important because they indicate how much we don't know about our data. Making inferences based on just a few cases is often unwise. In addition, many modelling procedures break down when missing values are involved and the corresponding rows will either have to be removed completely or the values need to be estimated somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surv = train[train['Survived']==1]\n",
    "nosurv = train[train['Survived']==0]\n",
    "surv_col = \"blue\"\n",
    "nosurv_col = \"red\"\n",
    "\n",
    "print(\"Survived: %i (%.1f percent), Not Survived: %i (%.1f percent), Total: %i\"\\\n",
    "      %(len(surv), 1.*len(surv)/len(train)*100.0,\\\n",
    "        len(nosurv), 1.*len(nosurv)/len(train)*100.0, len(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pearson Correlation Heatmap :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilise the Seaborn plotting package which allows us to plot heatmaps very conveniently as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that that the Pearson Correlation plot can tell us is that there are not too many features strongly correlated with one another. This is good from a point of view of feeding these features into your learning model because this means that there isn't much redundant or superfluous data in our training set and we are happy that each feature carries with it some unique information.\n",
    "\n",
    "\n",
    "The matrix gives us an overview as to which features are particularly interesting for our analysis. Both strongly positive or negative correlations with the Survived feature are valuable. Strong correlations between two other features would suggest that only one of them is necessary for our model (and including the other would in fact induce noise and potentially lead to over-fitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pairplots' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9d930a4ffea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPairplots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Pairplots' is not defined"
     ]
    }
   ],
   "source": [
    "Pairplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us generate some pairplots to observe the distribution of data from one feature to the other. Once again we use Seaborn to help us.\n",
    "\n",
    "\n",
    "This kind of plot is a more detailed visualisation of relationships between variables. It shows scatter plots for the different feature combinations plus a distribution of each feature on the diagonal. Again, the upper right and lower left triangle contain the same information. This kind of plot is vastly more useful for a set of continuous variables, instead of the categorical or integer values we have here. Nonetheless, it is a valuable exploratory tool that has a place in everyone's toolbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-95b783e113d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m g = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n\u001b[0m\u001b[1;32m      2\u001b[0m        u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\n\u001b[1;32m      3\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "cols = ['Survived','Pclass','Age','SibSp','Parch','Fare']\n",
    "g = sns.pairplot(data=train.dropna(), vars=cols, size=1.5,\n",
    "                 hue='Survived', palette=[nosurv_col,surv_col])\n",
    "# ou \n",
    "#g = sns.pairplot(train[[u'Survived', u'Pclass', u'Sex', u'Age', u'Parch', u'Fare', u'Embarked',\n",
    "#       u'FamilySize', u'Title']], hue='Survived', palette = 'seismic',size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\n",
    "g.set(xticklabels=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's most interesting to start with the strong signals in the correlation plot and to examine them more in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msurv = train[(train['Survived']==1) & (train['Sex']==\"male\")]\n",
    "fsurv = train[(train['Survived']==1) & (train['Sex']==\"female\")]\n",
    "mnosurv = train[(train['Survived']==0) & (train['Sex']==\"male\")]\n",
    "fnosurv = train[(train['Survived']==0) & (train['Sex']==\"female\")]\n",
    "\n",
    "plt.figure(figsize=[13,5])\n",
    "plt.subplot(121)\n",
    "sns.distplot(fsurv['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color=surv_col)\n",
    "sns.distplot(fnosurv['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color=nosurv_col,\n",
    "            axlabel='Female Age')\n",
    "plt.subplot(122)\n",
    "sns.distplot(msurv['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color=surv_col)\n",
    "sns.distplot(mnosurv['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color=nosurv_col,\n",
    "            axlabel='Male Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We study the correlation of Age with Pclass using a violin plot, which is also split between survived (right half) and not survived (left half). Check out the other visualisations in your forked copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#foo = combine['Age'].hist(by=combine['Pclass'], bins=np.arange(0,81,1),\n",
    "#                          layout=[3,1], sharex=True, figsize=[8,12])\n",
    "\n",
    "#foo = sns.boxplot(x=\"Pclass\", y=\"Age\", hue=\"Survived\", data=train)\n",
    "\n",
    "#sns.violinplot(x=\"Pclass\", y=\"Age\", data=combine, inner=None)\n",
    "#sns.swarmplot(x=\"Pclass\", y=\"Age\", data=combine, color=\"w\", alpha=.5)\n",
    "\n",
    "sns.violinplot(x=\"Pclass\", y=\"Age\", hue=\"Survived\", data=train, split=True)\n",
    "plt.hlines([0,10], xmin=-1, xmax=3, linestyles=\"dotted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Violin plots are a modified version of boxplots, where the shape is a \"kernel density estimate\" of the underlying distribution. These estimates are smoothed and therefore extend beyond the actual values (look closely at the dotted zero level). I have also indicated Age == 10, which we will use to define children (vs teenagers) in the engineering part below.\n",
    "\n",
    "For a view into Pclass vs Sex let's use a mosaic plot for a 2-dimensional overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy = mosaic(train,[\"Survived\",\"Sex\",\"Pclass\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will start to use factorplots, i.e. groups of pointplots, from the seaborn plotting package to visualise the categorical relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", col=\"Embarked\",\n",
    "                   data=train, aspect=0.9, size=3.5, ci=95.0)\n",
    "\n",
    "# for some reason in this plot the colours for m/f are flipped:\n",
    "#grid = sns.FacetGrid(train, col='Embarked', size=2.2, aspect=1.6)\n",
    "#grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', ci=95.0, palette='deep')\n",
    "#grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Let's follow up the numbers for Pclass vs Embarked with a pandas crosstab plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab = pd.crosstab(combine['Embarked'], combine['Pclass'])\n",
    "print(tab)\n",
    "dummy = tab.div(tab.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\n",
    "dummy = plt.xlabel('Port embarked')\n",
    "dummy = plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze by pivoting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm some of our observations and assumptions, we can quickly analyze our feature correlations by pivoting features against each other. We can only do so at this stage for features which do not have any empty values. It also makes sense doing so only for features which are categorical (Sex), ordinal (Pclass) or discrete (SibSp, Parch) type.\n",
    "\n",
    "    Pclass We observe significant correlation (>0.5) among Pclass=1 and Survived (classifying #3). We decide to include this feature in our model.\n",
    "\n",
    "    Sex We confirm the observation during problem definition that Sex=female had very high survival rate at 74% (classifying #1).\n",
    "\n",
    "    SibSp and Parch These features have zero correlation for certain values. It may be best to derive a feature or a set of features from these individual features (creating #1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a740b61b52b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pclass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pclass'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SibSp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SibSp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "\n",
    "train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "\n",
    "train_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "\n",
    "train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze by visualizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can continue confirming some of our assumptions using visualizations for analyzing the data.\n",
    "\n",
    "### Correlating numerical features\n",
    "Let us start by understanding correlations between numerical features and our solution goal (Survived).\n",
    "A histogram chart is useful for analyzing continous numerical variables like Age where banding or ranges will help identify useful patterns. The histogram can indicate distribution of samples using automatically defined bins or equally ranged bands. This helps us answer questions relating to specific bands (Did infants have better survival rate?)\n",
    "\n",
    "Note that x-axis in historgram visualizations represents the count of samples or passengers.\n",
    "\n",
    "#### Observations.\n",
    "    Infants (Age <=4) had high survival rate.\n",
    "    Oldest passengers (Age = 80) survived.\n",
    "    Large number of 15-25 year olds did not survive.\n",
    "    Most passengers are in 15-35 age range.\n",
    "#### Decisions.\n",
    "This simple analysis confirms our assumptions as decisions for subsequent workflow stages.\n",
    "\n",
    "    We should consider Age (our assumption classifying #2) in our model training.\n",
    "    Complete the Age feature for null values (completing #1).\n",
    "    We should band age groups (creating #3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(train_df, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating numerical and ordinal features\n",
    "We can combine multiple features for identifying correlations using a single plot. This can be done with numerical and categorical features which have numeric values.\n",
    "\n",
    "#### Observations.\n",
    "    Pclass=3 had most passengers, however most did not survive. Confirms our classifying assumption #2.\n",
    "    Infant passengers in Pclass=2 and Pclass=3 mostly survived. Further qualifies our classifying assumption #2.\n",
    "    Most passengers in Pclass=1 survived. Confirms our classifying assumption #3.\n",
    "    Pclass varies in terms of Age distribution of passengers.\n",
    "\n",
    "#### Decisions.\n",
    "    Consider Pclass for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating categorical features\n",
    "Now we can correlate categorical features with our solution goal.\n",
    "\n",
    "#### Observations.\n",
    "    Female passengers had much better survival rate than males. Confirms classifying (#1).\n",
    "    Exception in Embarked=C where males had higher survival rate. This could be a correlation between Pclass and Embarked and in turn Pclass and Survived, not necessarily direct correlation between Embarked and Survived.\n",
    "    Males had better survival rate in Pclass=3 when compared with Pclass=2 for C and Q ports. Completing (#2).\n",
    "    Ports of embarkation have varying survival rates for Pclass=3 and among male passengers. Correlating (#1).\n",
    "\n",
    "#### Decisions.\n",
    "    Add Sex feature to model training.\n",
    "    Complete and add Embarked feature to model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Embarked')\n",
    "grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\n",
    "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating categorical and numerical features\n",
    "We may also want to correlate categorical features (with non-numeric values) and numeric features. We can consider correlating Embarked (Categorical non-numeric), Sex (Categorical non-numeric), Fare (Numeric continuous), with Survived (Categorical numeric).\n",
    "\n",
    "#### Observations.\n",
    "    Higher fare paying passengers had better survival. Confirms our assumption for creating (#4) fare ranges.\n",
    "    Port of embarkation correlates with survival rates. Confirms correlating (#1) and completing (#2).\n",
    "\n",
    "#### Decisions.\n",
    "    Consider banding Fare feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})\n",
    "grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\n",
    "grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will see how the distributions of survivors and non-survivors compare. Personally, I like histograms for a first look at comparing two or more populations in case of scaled features. For categorical features we will use barplots plus standard deviation bars, to better judge the significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action=\"ignore\")\n",
    "plt.figure(figsize=[12,10])\n",
    "plt.subplot(331)\n",
    "sns.distplot(surv['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color=surv_col)\n",
    "sns.distplot(nosurv['Age'].dropna().values, bins=range(0, 81, 1), kde=False, color=nosurv_col,\n",
    "            axlabel='Age')\n",
    "plt.subplot(332)\n",
    "sns.barplot('Sex', 'Survived', data=train)\n",
    "plt.subplot(333)\n",
    "sns.barplot('Pclass', 'Survived', data=train)\n",
    "plt.subplot(334)\n",
    "sns.barplot('Embarked', 'Survived', data=train)\n",
    "plt.subplot(335)\n",
    "sns.barplot('SibSp', 'Survived', data=train)\n",
    "plt.subplot(336)\n",
    "sns.barplot('Parch', 'Survived', data=train)\n",
    "plt.subplot(337)\n",
    "sns.distplot(np.log10(surv['Fare'].dropna().values+1), kde=False, color=surv_col)\n",
    "sns.distplot(np.log10(nosurv['Fare'].dropna().values+1), kde=False, color=nosurv_col,axlabel='Fare')\n",
    "plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.35)\n",
    "\n",
    "print(\"Median age survivors: %.1f, Median age non-survivers: %.1f\"\\\n",
    "      %(np.median(surv['Age'].dropna()), np.median(nosurv['Age'].dropna())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we are creating a kind of summary dashboard, where we collect relevant visualisations to study the distributions of the individual features. We use the matplotlib subplot tool to line up the individual plots in a grid. We use overlapping histograms for ordinal features and barplots for categorical features. The barplots show the fraction of people (per group) who survived. There's a lot going on in this figure, so take your time to look at all the details.\n",
    "We learn the following things from studying the individual features:\n",
    "Age: The medians are identical. However, it's noticeable that fewer young adults have survived (ages 18 - 30-ish) whereas children younger than 10-ish had a better survival rate. Also, there are no obvious outliers that would indicate problematic input data. The highest ages are well consistent with the overall distribution. There is a notable shortage of teenagers compared to the crowd of younger kids. But this could have natural reasons.\n",
    "Pclass: There's a clear trend that being a 1st class passenger gives you better chances of survival. Life just isn't fair.\n",
    "SibSp & Parch: Having 1-3 siblings/spouses/parents/children on board (SibSp = 1-2, Parch = 1-3) suggests proportionally better survival numbers than being alone (SibSp + Parch = 0) or having a large family travelling with you.\n",
    "Embarked: Well, that does look more interesting than expected. Embarking at \"C\" resulted in a higher survival rate than embarking at \"S\". There might be a correlation with other variables, here though.\n",
    "Fare: This is case where a linear scaling isn't of much help because there is a smaller number of more extreme numbers. A natural choice in this case is to transform the values logarithmically. For this to work we need to adjust for the zero-fare entries. The plot tells us that the survival chances were much lower for the cheaper cabins. Naively, one would assume that those cheap cabins were mostly located deeper inside the ship, i.e. further away from the life boats.\n",
    "A little follow up: For SibSp we see in the plot that most of the differences are not very significant (overlapping error bars). Another way of checking the actual numbers are through cross tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab = pd.crosstab(train['SibSp'], train['Survived'])\n",
    "print(tab)\n",
    "#dummy = tab.div(tab.sum(1).astype(float), axis=0).plot(kind=\"bar\", \n",
    "#                         stacked=True, color=[nosurv_col,surv_col])\n",
    "#dummy = plt.xlabel('SibSp')\n",
    "#dummy = plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
